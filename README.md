# Agent Conversationnel RAG avec LangChain, Mistral AI, et Streamlit


## PrÃ©sentation

Ce projet propose un **chatbot intelligent**, conÃ§u pour rÃ©pondre Ã  des questions basÃ©es sur une base documentaire interne (PDFs techniques, manuels, documents de formation).  
Il utilise un pipeline **RAG** (Retrieval-Augmented Generation) combinant :

- **Mistral AI** (`mistral-large-latest` pour la gÃ©nÃ©ration de texte)
- **Mistral-Embed** pour les embeddings sÃ©mantiques
- **LangChain** pour l'orchestration de la recherche et du dialogue
- **FAISS** pour l'indexation vectorielle locale
- **Streamlit** pour l'interface web utilisateur

Le tout est **conteneurisÃ© avec Docker** afin d'assurer portabilitÃ©, reproductibilitÃ© et facilitÃ© de dÃ©ploiement.

---

## FonctionnalitÃ©s

- **Chat conversationnel contextuel** basÃ© sur l'historique
- **Recherche intelligente** dans les documents PDF internes
- **Extraction d'images et OCR** pour traiter des documents scannÃ©s
- **Interface utilisateur web** Streamlit responsive
- **Utilisation professionnelle de VS Code avec Docker**

---

## Architecture Technique

| Composant | Description | Technologies utilisÃ©es |
|:----------|:------------|:------------------------|
| **Indexation des Documents** | Analyse de fichiers PDF, dÃ©coupage en chunks, gÃ©nÃ©ration d'embeddings vectoriels | `embedder.py`, `embedder_with_OCR.py`, `pdf2image`, `pytesseract`, `Mistral-Embed`, `FAISS` |
| **RÃ©cupÃ©ration augmentÃ©e** (RAG) | Reformulation de question + rÃ©cupÃ©ration de documents pertinents | `LangChain` (`create_history_aware_retriever`, `create_retrieval_chain`) |
| **GÃ©nÃ©ration de rÃ©ponse** | Construction d'une rÃ©ponse basÃ©e sur les documents rÃ©cupÃ©rÃ©s | `ChatMistralAI` (`mistral-large-latest`) |
| **Interface utilisateur** | Application web interactive | `Streamlit` (`interface.py`) |
| **Orchestration** | Scripts et notebooks de gestion | `chatBot.py`, `multimodal_embedder.ipynb` |

---

## Pipeline RAG utilisÃ©

1. **Indexation**
    - Les fichiers PDF sont analysÃ©s, dÃ©coupÃ©s en segments (`chunk_size=1000`, `overlap=200`).
    - Chaque segment est encodÃ© en vecteur via **Mistral-Embed**.
    - Les vecteurs sont stockÃ©s dans **FAISS** (`faiss_index/`).

2. **Retrieval**
    - Lorsqu'une question est posÃ©e, elle est reformulÃ©e de maniÃ¨re contextuelle par **LangChain**.
    - Les chunks pertinents sont rÃ©cupÃ©rÃ©s via une recherche FAISS.

3. **GÃ©nÃ©ration**
    - Les passages retrouvÃ©s sont injectÃ©s dans un prompt structurÃ©.
    - Le modÃ¨le **Mistral Large** gÃ©nÃ¨re une rÃ©ponse complÃ¨te en franÃ§ais.

---

## Technologies

- **LangChain**
- **MistralAI (chat et embeddings)**
- **FAISS**
- **pdf2image**, **pytesseract**, **PyMuPDF**
- **Streamlit**
- **Docker / Docker Compose**
- **VS Code Remote Containers**

---

## Installation & Utilisation

### 1. PrÃ©requis

- Docker Desktop 24+
- Git 2.40+
- VS Code 1.85+ (extensions recommandÃ©es : *Dev Containers*, *Python*, *Jupyter*)
- Compte Mistral AI et clÃ© API valide

### 2. Cloner le dÃ©pÃ´t

```bash
git clone https://gitlab-df.imt-atlantique.fr/a24ounza/ai-agent.git
cd ai-agent
```

### 3. Configurer les variables d'environnement
#### CrÃ©er une clÃ© API de Mistral 
1. AccÃ©der Ã  [https://console.mistral.ai/home](https://console.mistral.ai/home). CrÃ©er un compte ou ce connecter avec un compte google.

![SideBar](assets\images\sidebar.png)

2. AccÃ©der Ã  `ClÃ©s API`. *
3. Il faudra choisir un plan pour activer un forfait. Choisissez le plan Experiment (Gratuit ).
4. AccÃ©pter les conditions et vÃ©rifier votre numÃ©ro de tÃ©lÃ©phone.
![alt text](assets\images\api_key.png)
5. Clicker sur `CrÃ©er une nouvelle clÃ©`. Choisir un nom pour la clÃ© et une date d'expiration (Jamais).
6. Copier la clÃ© et garder la.
#### Executer la commande 
```bash
echo MISTRAL_API_KEY="Votre clÃ© API ici" > .env
```
## ðŸ” Configuration de `config.yaml` pour l'authentification

Cette application utilise [`streamlit-authenticator`](https://github.com/mkhorasani/streamlit-authenticator) pour gÃ©rer la connexion et les sessions utilisateurs.  
Pour sÃ©curiser vos identifiants et les cookies de session, suivez les Ã©tapes ci-dessous pour crÃ©er votre propre `config.yaml`.

### 1. âŒ Ne pas utiliser directement `config.example.yaml`

Ce fichier est un modÃ¨le. Vous devez crÃ©er votre **propre version sÃ©curisÃ©e** et ne jamais la publier dans Git.

### 2. âœ… CrÃ©ez un fichier `config.yaml`

CrÃ©ez un fichier `config.yaml` Ã  la racine du projet Ã  partir du modÃ¨le :

```bash
cp config.example.yaml config.yaml
```

Modifiez les valeurs Ã  lâ€™intÃ©rieur, en particulier :

#### ðŸ” GÃ©nÃ©rer une `cookie.key` sÃ©curisÃ©e

Cette clÃ© permet de signer les cookies de session afin dâ€™empÃªcher toute falsification. Elle doit :

- Contenir au moins 16 caractÃ¨res alÃ©atoires
- Rester secrÃ¨te (ne jamais la publier)
- ÃŠtre unique pour chaque instance

Pour en gÃ©nÃ©rer une avec Python :

```python
import secrets
print(secrets.token_urlsafe(32))
```

Collez la chaÃ®ne gÃ©nÃ©rÃ©e dans votre `config.yaml` :

```yaml
cookie:
  name: streamlit_auth
  key: "clÃ©_sÃ©curisÃ©e_gÃ©nÃ©rÃ©e_ici"
  expiry_days: 7
```
#### Ã‰tapes :

1. Ouvrir le fichier :

```bash
nano config.yaml
```

2. Naviguer avec les flÃ¨ches et modifier par exemple :

```yaml
password: "$2b$12$nouveau_hash_bcrypt"
key: "nouvelle_clÃ©_cookie_secure"
```

3. Enregistrer : `Ctrl + O` puis `EntrÃ©e`  
4. Quitter : `Ctrl + X`

âœ… Cette mÃ©thode est pratique et rapide pour faire de petits changements sans quitter le terminal.

âš ï¸ Attention Ã  lâ€™indentation : utilisez **des espaces, pas de tabulations**, et gardez les niveaux de retrait YAML intacts.
### 4. ðŸ›¡ï¸ Ajoutez `config.yaml` au `.gitignore`

Dans votre fichier `.gitignore`, ajoutez :

```
config.yaml
```

Cela empÃªchera toute fuite accidentelle dâ€™informations sensibles.

### âœ… RÃ©sumÃ©

| Fichier                | Doit Ãªtre publiÃ© ? | Remarques                           |
|------------------------|--------------------|-------------------------------------|
| `config.example.yaml` | âœ… Oui             | Fichier modÃ¨le, sans donnÃ©es rÃ©elles |
| `config.yaml`          | âŒ Non             | Contient des secrets â€” **ne pas publier** |

### 4. Construction des images Docker

```bash
docker compose build
```

### 5. Lancer les conteneurs

- **Shell de dÃ©veloppement (Obligatoire pour accÃ©der et mofifier le code)** :
```bash
docker compose up dev
```
- **JupyterLab (Si vous voulez utiliser ou ajouter des notebooks Jupyter)** :
```bash
docker compose up jupyter
```
Puis ouvrir [http://localhost:8888](http://localhost:8888)

- **Streamlit (Pour lancer le Chatbot)** :
```bash
docker compose up streamlit
```
Puis ouvrir [http://localhost:8501](http://localhost:8501)


### 7. Utiliser VS Code avec les conteneurs

- Ouvrir `ai-agent/` dans VS Code.
- `F1` > **Dev Containers: Reopen in Container**.
- Travailler directement dans l'environnement conteneurisÃ©.

---

## Arborescence du projet

```bash
ai-agent/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ docs/
â”œâ”€â”€ faiss_index/
â”œâ”€â”€ workspace/
â”‚   â”œâ”€â”€ chatBot.py
â”‚   â”œâ”€â”€ embedder.py
â”‚   â”œâ”€â”€ embedder_with_OCR.py
â”‚   â”œâ”€â”€ multimodal_embedder.ipynb
|   â”œâ”€â”€ interface.py
```
