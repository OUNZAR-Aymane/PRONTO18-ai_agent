{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_mistralai.embeddings import MistralAIEmbeddings\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from tqdm import tqdm\n",
    "from typing import TypedDict, Annotated\n",
    "sys.path.insert(0, str(Path().resolve().parent / \"app\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34bc0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment\n",
    "print(\"Chargement de l'environnement...\")\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "json_in = Path().resolve()/ \"QA_pairs.json\"\n",
    "index_path = Path().resolve().parent / \"document_index.json\"\n",
    "faiss_path = Path().resolve().parent / \"faiss_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ad314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose if ypu want to use RAG or not\n",
    "use_rag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaafb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chargement des composants du chatbot...\")\n",
    "model = ChatMistralAI(mistral_api_key=api_key, model=\"mistral-large-latest\")\n",
    "embedding_fn = MistralAIEmbeddings(model=\"mistral-embed\", mistral_api_key=api_key)\n",
    "vector = FAISS.load_local(faiss_path, embeddings=embedding_fn, allow_dangerous_deserialization=True)\n",
    "\n",
    "if use_rag:\n",
    "    system_instruction_rag = \"\"\"\n",
    "    Tu es l’assistant de l’observatoire astronomique de l’IMT Atlantique (campus de Brest).\n",
    "    Règles impératives :\n",
    "    1. Réponds en français, en **trois phrases maximum**.\n",
    "    2. Appuie-toi *exclusivement* sur le CONTEXTE fourni ; si l’info n’y est pas, réponds : « Je ne sais pas. »\n",
    "    3. Toute formule → encadrée par des dollars : $\\,E = mc^2\\,$.\n",
    "    4. Tu donne des réponses **précises** et **concises**.\n",
    "    CONTEXTE :\n",
    "    {context}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_rag = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_instruction_rag.strip()),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    retriever  = vector.as_retriever()\n",
    "\n",
    "    document_chain = create_stuff_documents_chain(model, prompt_rag)\n",
    "    chain_rag = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "    def rag_get_response(question, chain=chain_rag):\n",
    "        while True :\n",
    "            try:\n",
    "                response = chain.invoke({\"input\": question})\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de l'appel à l'API : {e}\")\n",
    "        return response['answer']\n",
    "else :\n",
    "    system_instruction_norag = \"\"\"\n",
    "    Tu es l’assistant de l’observatoire astronomique de l’IMT Atlantique (campus de Brest).\n",
    "    Tu ne disposes pas des documents complets ; réponds uniquement sur la base de tes connaissances internes.\n",
    "    Contraintes :\n",
    "    1. Français, trois phrases maximum.\n",
    "    2. Formules mathématiques encadrées par des dollars (LaTeX).\n",
    "    3. Ne cite aucune source.\n",
    "    4. Si l’information précise n’est pas certaine, dis : « Je ne sais pas. »\n",
    "    5. Tu donne des réponses **précises** et **concises**.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_norag = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_instruction_norag.strip()),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "    output_parser = StrOutputParser()\n",
    "    chain_norag = prompt_norag | model | output_parser\n",
    "\n",
    "    def no_rag_get_response(question, chain=chain_norag):\n",
    "        while True :\n",
    "            try:\n",
    "                response = chain.invoke({\"input\": question})\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de l'appel à l'API : {e}\")\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea56d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chargement des paires QA depuis QA_pairs.json...\")\n",
    "with open(index_path, encoding=\"utf-8\") as f:\n",
    "    doc_index = json.load(f)             # doc_name → UUID\n",
    "\n",
    "with open(json_in, encoding=\"utf-8\") as f:\n",
    "    raw_pairs = json.load(f)\n",
    "\n",
    "pairs = []\n",
    "for p in raw_pairs:\n",
    "    if not p.get(\"support_doc_ids\"):\n",
    "        uuid_ = doc_index.get(p[\"doc_name\"])\n",
    "        p[\"support_doc_ids\"] = [uuid_] if uuid_ else []\n",
    "    pairs.append(p)\n",
    "\n",
    "lookup = {p[\"question\"]: p for p in pairs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ce352",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = \"rag_eval_results.csv\" if use_rag else \"no_rag_eval_results.csv\"\n",
    "\n",
    "csv  = Path().resolve() / csv_name\n",
    "if os.path.exists(csv):\n",
    "    df = pd.read_csv(csv)\n",
    "else :\n",
    "    df = pd.DataFrame(raw_pairs)\n",
    "\n",
    "df[\"support_doc_ids\"]  = df[\"question\"].map(lambda q: lookup[q][\"support_doc_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(csv, index=False)\n",
    "print(f\"Fichier CSV enregistré : {csv_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e54d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exécution du chatbot pour générer les prédictions...\")\n",
    "chat_history = []\n",
    "predictions, latencies = [], []\n",
    "for row in tqdm(df.itertuples(), total=len(df)):\n",
    "        if use_rag:\n",
    "                start = time.time()\n",
    "                result = rag_get_response(row.question)\n",
    "        else :\n",
    "                start = time.time()\n",
    "                result = no_rag_get_response(row.question)\n",
    "        latencies.append(time.time() - start)\n",
    "        predictions.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7cf922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prediction'] = predictions\n",
    "df['latency'] = latencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f693e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "df.to_csv(csv_name, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\nRésultats sauvegardés dans : {csv_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Configuration des prompts d'évaluation...\")\n",
    "class EvalNote(TypedDict):\n",
    "    note:        Annotated[float,  \"de 0 à 5\"]\n",
    "    explication: Annotated[str,    \"raisonnement concis\"]\n",
    "\n",
    "model_strict = model.with_structured_output(EvalNote, strict=True)\n",
    "\n",
    "\n",
    "correctness_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Tu es un professeur qui note la justesse factuelle.\n",
    "Donne une note de 0 (totalement faux) à 5 (parfaitement correct).\n",
    "Réponds **obligatoirement** au format JSON suivant :\n",
    "\n",
    "{{\n",
    "  \"note\": <nombre>,\n",
    "  \"explication\": \"<justification courte>\"\n",
    "}}\n",
    "\n",
    "QUESTION :\n",
    "{question}\n",
    "\n",
    "RÉPONSE ATTENDUE :\n",
    "{reference}\n",
    "\n",
    "RÉPONSE DU CHATBOT :\n",
    "{prediction}\n",
    "\n",
    "JSON :\n",
    "\"\"\")\n",
    "\n",
    "relevance_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Tu es un professeur. Donne une note de 0 (hors-sujet) à 5 (parfaitement pertinent).\n",
    "Réponds **obligatoirement** au format JSON suivant :\n",
    "\n",
    "{{\n",
    "  \"note\": <nombre>,\n",
    "  \"explication\": \"<justification courte>\"\n",
    "}}\n",
    "\n",
    "QUESTION :\n",
    "{question}\n",
    "\n",
    "RÉPONSE DU CHATBOT :\n",
    "{prediction}\n",
    "\n",
    "JSON :\n",
    "\"\"\")\n",
    "\n",
    "faithfulness_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Tu es un évaluateur. Les informations de la réponse proviennent-elles bien des documents ?\n",
    "Donne une note de 0 (hallucination complète) à 5 (entièrement fondé sur le contexte).\n",
    "Réponds **obligatoirement** au format JSON suivant :\n",
    "\n",
    "{{\n",
    "  \"note\": <nombre>,\n",
    "  \"explication\": \"<justification courte>\"\n",
    "}}\n",
    "                                                   \n",
    "DOCUMENTS :\n",
    "{docs}\n",
    "\n",
    "RÉPONSE DU CHATBOT :\n",
    "{prediction}\n",
    "\n",
    "JSON :\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9deee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initialisation des chaînes LLM pour l'évaluation...\")\n",
    "correctness_chain  = correctness_prompt  | model_strict\n",
    "relevance_chain    = relevance_prompt    | model_strict\n",
    "faithfulness_chain = faithfulness_prompt | model_strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Évaluation des réponses du chatbot...\")\n",
    "notes_correct, notes_relev, notes_faith = [], [], []\n",
    "exps_correct,  exps_relev,  exps_faith  = [], [], []\n",
    "\n",
    "for row in tqdm(df.itertuples(), total=len(df), desc=\"Évaluation\"):\n",
    "\n",
    "    docs = vector.similarity_search(row.question, k=4)\n",
    "    ctx  = \"\\n\\n\".join(d.page_content for d in docs)\n",
    "    while True:\n",
    "        try : \n",
    "            # --- Correctness\n",
    "            res = correctness_chain.invoke({\n",
    "                \"question\":  row.question,\n",
    "                \"reference\": row.answer,\n",
    "                \"prediction\":row.prediction,\n",
    "            })\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'appel à l'API : {e}\")\n",
    "    notes_correct.append(res[\"note\"]) \n",
    "    exps_correct.append(res[\"explication\"])  \n",
    "    while True:\n",
    "        try : \n",
    "            # --- Relevance\n",
    "            res = relevance_chain.invoke({\n",
    "                \"question\":  row.question,\n",
    "                \"prediction\":row.prediction,\n",
    "            })\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'appel à l'API : {e}\")\n",
    "    notes_relev.append(res[\"note\"])\n",
    "    exps_relev.append(res[\"explication\"])\n",
    "    while True:\n",
    "        try : \n",
    "            # --- Faithfulness / groundedness\n",
    "            res = faithfulness_chain.invoke({\n",
    "                \"docs\":       ctx,\n",
    "                \"prediction\": row.prediction,\n",
    "            })\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'appel à l'API : {e}\")\n",
    "    notes_faith.append(res[\"note\"])\n",
    "    exps_faith.append(res[\"explication\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd661f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"note_correct\"]       = notes_correct\n",
    "df[\"note_relevance\"]     = notes_relev\n",
    "df[\"note_faithfulness\"]  = notes_faith\n",
    "\n",
    "df[\"explication_correct\"]      = exps_correct\n",
    "df[\"explication_relevance\"]    = exps_relev\n",
    "df[\"explication_faithfulness\"] = exps_faith\n",
    "\n",
    "df.to_csv(csv, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = []\n",
    "st_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "for row in tqdm(df.itertuples(), total=len(df), desc=\"Évaluation\"):\n",
    "    sims.append(util.cos_sim(\n",
    "        st_model.encode(row.prediction, convert_to_tensor=True),\n",
    "        st_model.encode(row.answer,     convert_to_tensor=True)\n",
    "    ).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "df[\"semantic_sim\"] = sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61507ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "df.to_csv(csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\nRésultats sauvegardés dans : {csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549456bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nRésultats de l'évaluation :\\n\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 2)\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
